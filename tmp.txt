07/04 11:35:32 - OpenCompass - INFO - Task [Qwen3-8B/openai_humaneval]
07/04 11:35:36 - OpenCompass - WARNING - Max Completion tokens for /mnt/data/Llmei/data/Qwen/Qwen3-8B is :16384

Downloading [README.md]:   0%|          | 0.00/6.52k [00:00<?, ?B/s]
Downloading [README.md]: 100%|██████████| 6.52k/6.52k [00:00<00:00, 17.5MB/s]

Downloading data:   0%|          | 0.00/83.9k [00:00<?, ?B/s]
Downloading data: 100%|██████████| 83.9k/83.9k [00:00<00:00, 2.72MB/s]

Generating test split:   0%|          | 0/164 [00:00<?, ? examples/s]
Generating test split: 100%|██████████| 164/164 [00:00<00:00, 37349.51 examples/s]
07/04 11:35:45 - OpenCompass - INFO - Start inferencing [Qwen3-8B/openai_humaneval]
[2025-07-04 11:35:45,490] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting build dataloader
[2025-07-04 11:35:45,491] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting inference process...

  0%|          | 0/1 [00:00<?, ?it/s]
  0%|          | 0/1 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/opencompass/tasks/openicl_infer.py", line 161, in <module>
    inferencer.run()
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/opencompass/tasks/openicl_infer.py", line 89, in run
    self._inference()
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/opencompass/tasks/openicl_infer.py", line 134, in _inference
    inferencer.inference(retriever,
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/opencompass/openicl/icl_inferencer/icl_gen_inferencer.py", line 153, in inference
    results = self.model.generate_from_template(
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/opencompass/models/base.py", line 201, in generate_from_template
    return self.generate(inputs, max_out_len=max_out_len, **kwargs)
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/opencompass/models/openai_api.py", line 176, in generate
    results = list(
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/concurrent/futures/_base.py", line 621, in result_iterator
    yield _result_or_cancel(fs.pop())
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/concurrent/futures/_base.py", line 319, in _result_or_cancel
    return fut.result(timeout)
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/concurrent/futures/_base.py", line 458, in result
    return self.__get_result()
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/concurrent/futures/thread.py", line 58, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/opencompass/models/openai_api.py", line 302, in _generate
    raw_response = requests.post(self.url,
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/requests/sessions.py", line 697, in send
    adapter = self.get_adapter(url=request.url)
  File "/home/pyhou/miniconda3/envs/evalscope/lib/python3.10/site-packages/requests/sessions.py", line 792, in get_adapter
    raise InvalidSchema(f"No connection adapters were found for {url!r}")
requests.exceptions.InvalidSchema: No connection adapters were found for "['http://127.0.0.1:9160/v1/chat/completions']"
